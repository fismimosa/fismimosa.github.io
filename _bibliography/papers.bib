---
---

@article{longo2024manifesto,
  author       = {Luca Longo and
                  Mario Brcic and
                  Federico Cabitza and
                  Jaesik Choi and
                  Roberto Confalonieri and
                  Javier Del Ser and
                  Riccardo Guidotti and
                  Yoichi Hayashi and
                  Francisco Herrera and
                  Andreas Holzinger and
                  Richard Jiang and
                  Hassan Khosravi and
                  Freddy L{\'{e}}cu{\'{e}} and
                  Gianclaudio Malgieri and
                  Andr{\'{e}}s P{\'{a}}ez and
                  Wojciech Samek and
                  Johannes Schneider and
                  Timo Speith and
                  Simone Stumpf},
abbr=          {Inf. Fusion},  
title        = {Explainable Artificial Intelligence {(XAI)} 2.0: {A} manifesto of
                  open challenges and interdisciplinary research directions},
  abstract     = {Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders.}, 
  journal      = {Information Fusion},
  volume       = {106},
  pages        = {102301},
  year         = {2024},
  url          = {https://doi.org/10.1016/j.inffus.2024.102301},
  doi          = {10.1016/J.INFFUS.2024.102301},
  timestamp    = {Sun, 04 Aug 2024 19:49:40 +0200},
  biburl       = {https://dblp.org/rec/journals/inffus/LongoBCCCSGHHHJKLMPSSSS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}, 
  selected={true},
  bibtex_show={true}
}

@article{berti2024role,
  abbr={Quantum},
  title={The role of encodings and distance metrics for the quantum nearest neighbor},
  abstract={Over the past few years, we observed a rethinking of classical artificial intelligence algorithms from a quantum computing perspective. This trend is driven by the peculiar properties of quantum mechanics, which offer the potential to enhance artificial intelligence capabilities, enabling it to surpass the constraints of classical computing. However, redesigning classical algorithms into their quantum equivalents is not straightforward and poses numerous challenges. In this study, we analyze in-depth two orthogonal designs of the quantum K-nearest neighbor classifier. In particular, we show two solutions based on amplitude encoding and basis encoding of data, respectively. These two types of encoding impact the overall structure of the respective algorithms, which employ different distance metrics and show different performances. By breaking down each quantum algorithm, we clarify and compare implementation aspects ranging from data preparation to classification. Eventually, we discuss the difficulties associated with data preparation, the theoretical advantage of quantum algorithms, and their impact on performance with respect to the classical counterpart.},
  author={Berti, Alessandro and Bernasconi, Anna and Del Corso, Gianna M and Guidotti, Riccardo},
  journal={Quantum Machine Intelligence},
  volume={6},
  number={2},
  pages={62},
  year={2024},
  publisher={Springer},
  selected={true},
  bibtex_show={true}
}

@article{piaggesi2024counterfactual,
  abbr={IEEE},
  title={Counterfactual and Prototypical Explanations for Tabular Data via Interpretable Latent Space},
  author={Piaggesi, Simone and Bodria, Francesco and Guidotti, Riccardo and Giannotti, Fosca and Pedreschi, Dino},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE},
  selected={true},
  bibtex_show={true}
}

@article{bernasconi2024quantum,
  abbr={Quantum},
  title={Quantum subroutine for variance estimation: algorithmic design and applications},
  abstract={Quantum computing sets the foundation for new ways of designing algorithms, thanks to the peculiar properties inherited by quantum mechanics. The exploration of this new paradigm faces new challenges concerning which field quantum speedup can be achieved. Toward finding solutions, looking for the design of quantum subroutines that are more efficient than their classical counterpart poses solid pillars to new powerful quantum algorithms. Herewith, we delve into a grounding subroutine, the computation of the variance, whose usefulness spaces across different fields of application, particularly the artificial intelligence (AI) one. Indeed, the finding of the quantum counterpart of these building blocks impacts vertically those algorithms that leverage this metric. In this work, we propose QVAR, a quantum subroutine, to compute the variance that exhibits a logarithmic complexity both in the circuit depth and width, excluding the state preparation cost. With the vision of showing the use of QVAR as a subroutine for new quantum algorithms, we tackle two tasks from the AI domain: feature selection and outlier detection. In particular, we showcase two AI hybrid quantum algorithms that leverage QVAR: the hybrid quantum feature selection (HQFS) algorithm and the quantum outlier detection algorithm (QODA). In this manuscript, we describe the implementation of QVAR, HQFS, and QODA, providing their correctness and complexities and showing the effectiveness of these hybrid quantum algorithms with respect to their classical counterpart.},
  author={Bernasconi, Anna and Berti, Alessandro and Del Corso, Gianna M and Guidotti, Riccardo and Poggiali, Alessandro},
  journal={Quantum Machine Intelligence},
  volume={6},
  doi={10.1007/s42484-024-00213-9},
  number={2},
  pages={78},
  year={2024},
  publisher={Springer},
  selected={true},
  bibtex_show={true}
}

@article{spinnato2024fast,
  abbr={IEEE},
  title={Fast, Interpretable and Deterministic Time Series Classification with a Bag-Of-Receptive-Fields},
  author={Spinnato, Francesco and Guidotti, Riccardo and Monreale, Anna and Nanni, Mirco},
  abstract={The current trend in the literature on Time Series Classification is to develop increasingly accurate algorithms by combining multiple models in ensemble hybrids, representing time series in complex and expressive feature spaces, and extracting features from different representations of the same time series. As a consequence of this focus on predictive performance, the best time series classifiers are black-box models, which are not understandable from a human standpoint. Even the approaches that are regarded as interpretable, such as shapelet-based ones, rely on randomization to maintain computational efficiency. This poses challenges for interpretability, as the explanation can change from run to run. Given these limitations, we propose the Bag-Of-Receptive-Field (BORF), a fast, interpretable, and deterministic time series transform. Building upon the classical Bag-Of-Patterns, we bridge the gap between convolutional operators and discretization, enhancing the Symbolic Aggregate Approximation (SAX) with dilation and stride, which can more effectively capture temporal patterns at multiple scales. We propose an algorithmic speedup that reduces the time complexity associated with SAX-based classifiers, allowing the extension of the Bag-Of-Patterns to the more flexible Bag-Of-Receptive-Fields, represented as a sparse multivariate tensor. The empirical results from testing our proposal on more than 150 univariate and multivariate classification datasets demonstrate good accuracy and great computational efficiency compared to traditional SAX-based methods and state-of-the-art time series classifiers, while providing easy-to-understand explanations.},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE},
  selected={true},
  bibtex_show={true}
}

@inproceedings{cascione2024data,
  abbr={ECML},
  title={Data-Agnostic Pivotal Instances Selection for Decision-Making Models},
  author={Cascione, Alessio and Setzu, Mattia and Guidotti, Riccardo},
  abstract={As decision-making processes become increasingly complex, machine learning tools have become essential resources for tackling business and social issues. However, many methodologies rely on complex models that experts and everyday users cannot really interpret or understand. This is why constructing interpretable models is crucial. Humans typically make decisions by comparing the case at hand with a few exemplary and representative cases imprinted in their minds. Our objective is to design an approach that can select such exemplary cases, which we call pivots, to build an interpretable predictive model. To this aim, we propose a hierarchical and interpretable pivot selection model inspired by Decision Trees, and based on the similarity between pivots and input instances. Such a model can be used both as a pivot selection method, and as a standalone predictive model. By design, our proposal can be applied to any data type, as we can exploit pre-trained networks for data transformation. Through experiments on various datasets of tabular data, texts, images, and time series, we have demonstrated the superiority of our proposal compared to naive alternatives and state-of-the-art instance selectors, while minimizing the model complexity, i.e., the number of pivots identified.},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={367--386},
  year={2024},
  organization={Springer},
  selected={true},
  bibtex_show={true}
}

@article{guidotti2024generative,
    abbr={AAAI},
    title={Generative Model for Decision Trees},
    volume={38},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/30104},
    doi={10.1609/aaai.v38i19.30104},
    abstract={Decision trees are among the most popular supervised models due to their interpretability and knowledge representation resembling human reasoning. Commonly-used decision tree induction algorithms are based on greedy top-down strategies. Although these approaches are known to be an efficient heuristic, the resulting trees are only locally optimal and tend to have overly complex structures. On the other hand, optimal decision tree algorithms attempt to create an entire decision tree at once to achieve global optimality. We place our proposal between these approaches by designing a generative model for decision trees. Our method first learns a latent decision tree space through a variational architecture using pre-trained decision tree models. Then, it adopts a genetic procedure to explore such latent space to find a compact decision tree with good predictive performance. We compare our proposal against classical tree induction methods, optimal approaches, and ensemble models. The results show that our proposal can generate accurate and shallow, i.e., interpretable, decision trees.}, number={19}, journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Guidotti, Riccardo and Monreale, Anna and Setzu, Mattia and Volpi, Giulia},
    year={2024}, month={Mar.},
    pages={21116-21124},
    selected={true},
    bibtex_show={true}
}


